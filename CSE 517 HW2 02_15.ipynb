{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled1.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"IEvXQk8AaNjq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"add85fe4-40ad-44fc-9938-d17b09d27a74","executionInfo":{"status":"ok","timestamp":1550297288370,"user_tz":480,"elapsed":392,"user":{"displayName":"Zhanlin Liu","photoUrl":"","userId":"07295131763425127630"}}},"cell_type":"code","source":["#### Import packages and set working directory\n","import pandas as pd\n","import os\n","from google.colab import drive\n","import random\n","import re\n","import math\n","import numpy as np\n","\n","drive.mount('/content/drive/')\n","os.getcwd()\n","os.chdir('/content/drive/My Drive/cse517/hw2')"],"execution_count":49,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"d99j-icZaPyv","colab_type":"code","colab":{}},"cell_type":"code","source":["#############################################\n","########### Data Preprocessing ##############\n","#############################################\n","#### Function which reads in json file \n","import json\n","def read_dataset(filename):\n","\twith open(filename,'r') as lines:\n","\t\tdataset = [json.loads(line) for line in lines]\n","\tlines.close()\n","\treturn dataset"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6JBdpXygaRDb","colab_type":"code","colab":{}},"cell_type":"code","source":["### Import training set, dev set, and test set\n","train = read_dataset(\"twt.train.json\")\n","dev = read_dataset(\"twt.dev.json\")\n","test = read_dataset(\"twt.test.json\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"P82nHgE9aScE","colab_type":"code","colab":{}},"cell_type":"code","source":["### Add START and STOP in each sentence\n","SENTENCE_END = \"</s>\"\n","SENTENCE_START = [\"<s>\", 'START_1']\n","SENTENCE_START_2 = [\"<ss>\", 'START_2']\n","for i in range(len(train)):\n","  train[i].insert(0, SENTENCE_START)\n","  train[i].insert(0, SENTENCE_START_2)\n","  train[i].append(['</s>', 'STOP'])\n","  \n","for i in range(len(dev)):\n","  dev[i].insert(0, SENTENCE_START)\n","  dev[i].insert(0, SENTENCE_START_2)\n","  dev[i].append(['</s>', 'STOP'])\n","  \n","for i in range(len(test)):\n","  test[i].insert(0, SENTENCE_START)\n","  test[i].insert(0, SENTENCE_START_2)\n","  test[i].append(['</s>', 'STOP'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"m19aHxwpaVlS","colab_type":"code","colab":{}},"cell_type":"code","source":["### get Unigram state and bigram state \n","unigram_word = dict()\n","bigram_state = dict()\n","unigram_state = dict()\n","#unigram_emission = dict()\n","for sentence in train:\n","  previous_state = None\n","  for word, state in sentence:\n","    unigram_state[state] = unigram_state.get(state, 0) + 1\n","    unigram_word[word] = unigram_word.get(word, 0) +1\n","    #unigram_emission[(word, state)] = unigram_emission.get((word, state), 0 ) +1\n","    if previous_state != None and previous_state != 'STOP':\n","      bigram_state[(previous_state, state)] = bigram_state.get((previous_state, state), 0) +1\n","    previous_state = state\n","      "],"execution_count":0,"outputs":[]},{"metadata":{"id":"Xu1YtjVoaZUH","colab_type":"code","colab":{}},"cell_type":"code","source":["### Obtain the low frequent words \n","unigram_word_copy = dict(unigram_word)\n","low_freq =5 \n","low_freq_word ={}\n","for (key, value) in unigram_word_copy.items():\n","  if value <= low_freq:\n","    low_freq_word[key] = value\n","    del unigram_word[key]\n","\n","present_word = unigram_word.keys()  \n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ihLMXToIabNN","colab_type":"code","colab":{}},"cell_type":"code","source":["#############################################\n","################ OOV Rules #################\n","#############################################\n","\n","### Convert low frequent words into different classes based on different rules\n","def get_type(word):\n","  if \"#\" in word:\n","    return(\"hash\")\n","  elif \"@\" in word:\n","    return(\"R@\")\n","  elif \"https\" in word:\n","    return(\"link##\")\n","  elif any(i.isdigit() for i in word):\n","    return(\"number$%\")\n","  elif \":\" in word:\n","    return(\":word\")\n","  else:\n","    return(\"<UNK>\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hxH_SChcacYo","colab_type":"code","colab":{}},"cell_type":"code","source":["### Convert the low frequent words into different classes and update the unigram \n","train_low_freq_word = {}\n","for i in low_freq_word.keys():\n","  new_type = get_type(i)\n","  train_low_freq_word[new_type] = train_low_freq_word.get(new_type, 0) + low_freq_word[i] \n","\n","unigram_word.update(train_low_freq_word)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lms9TAcOaeS-","colab_type":"code","colab":{}},"cell_type":"code","source":["### Construct unigram emission probability \n","unigram_emission = dict()\n","for sentence in train:\n","  for word, state in sentence:\n","    if word not in present_word:\n","      new_type = get_type(word)\n","      unigram_emission[(new_type, state)] = unigram_emission.get((new_type, state), 0 ) +1\n","    else:\n","      unigram_emission[(word, state)] = unigram_emission.get((word, state), 0 ) +1\n","     "],"execution_count":0,"outputs":[]},{"metadata":{"id":"PN2_jiqmwTVY","colab_type":"code","colab":{}},"cell_type":"code","source":["for i in range(len(train)):\n","  for j in range(len(train[i])):\n","    if train[i][j][0] not in present_word:\n","      train[i][j][0] = get_type(train[i][j][0])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Bd0kTo5Xafwl","colab_type":"code","colab":{}},"cell_type":"code","source":["### Convert low frequent words in dev set\n","for i in range(len(dev)):\n","  for j in range(len(dev[i])):\n","    if dev[i][j][0] not in present_word:\n","      dev[i][j][0] = get_type(dev[i][j][0])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-OjlZ_L7ah-2","colab_type":"code","colab":{}},"cell_type":"code","source":["### Bigram HMM probability for states\n","unique_state_length = len(unigram_state.keys()) -3 \n","def calculate_bigramHMM_probability_LP(previous_state, state):\n","  if unigram_state.get(state, 0) ==0:\n","    return(1/unique_state_length)\n","  else:\n","    bigram_state_numerator = bigram_state.get((previous_state, state), 0) \n","    bigram_state_denominator = unigram_state.get(previous_state) \n","    return(bigram_state_numerator/bigram_state_denominator)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TdHanXa7ajON","colab_type":"code","colab":{}},"cell_type":"code","source":["### Unigram HMM probability for state\n","unigram_state_corpus = sum(unigram_state.values()) - unigram_state['STOP'] - unigram_state['START_1'] -  unigram_state['START_2']\n","def calculate_unigramHMM_probability_LP(state):\n","    unigram_state_numerator = unigram_state.get(state, 0) \n","    unigram_state_denominator = unigram_state_corpus\n","    return(unigram_state_numerator/unigram_state_denominator)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"L9U8gUCaakss","colab_type":"code","colab":{}},"cell_type":"code","source":["### Linear interpolation smooth \n","def calculate_interpolationHMM_probability(previous_state, state):\n","  bi_prob = calculate_bigramHMM_probability_LP(previous_state, state)\n","  uni_prob = calculate_unigramHMM_probability_LP(state)\n","  res = lambda_1 * bi_prob + lambda_2 * uni_prob \n","  return(res)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SaLN0Sn2amSc","colab_type":"code","colab":{}},"cell_type":"code","source":["### Emission probability \n","def calculate_emissionHMM_probability_LP(word, state):\n","  emission_numerator = unigram_emission.get((word, state),0)\n","  emission_denominator = unigram_state[state]\n","  return(emission_numerator/emission_denominator)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7TaQI99Nanys","colab_type":"code","colab":{}},"cell_type":"code","source":["###################################################\n","########### Bigram Viterbi algorithm ##############\n","##################################################\n","### Viterbi algorithm to get the pi matrix \n","lambda_1 = 0.6\n","lambda_2 = 0.4\n","unique_state = unigram_state.keys()\n","def viterbi_deconding(text):\n","  V= [{}]\n","  prev = None\n","  for state in unique_state:\n","    if state == \"START_1\":\n","      V[0][state] = {\"prob\":1, \"prev\":None}\n","    else:\n","      V[0][state] = {\"prob\":0, \"prev\":None}\n","  \n","  for i in range(1, len(text)):\n","    V.append({})\n","    for state in unique_state:\n","      V[i][state] = {\"prob\":0, \"prev\":None}\n","    for state in unique_state:\n","      max_prob = 0\n","      for prev in unique_state:\n","        prob = V[i-1][prev]['prob'] * calculate_emissionHMM_probability_LP(text[i][0], state) * calculate_interpolationHMM_probability(prev, state)\n","        if prob > max_prob:\n","          V[i][state] = {\"prob\": prob, \"prev\":prev}\n","          max_prob = prob          \n","  return(V)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Crpq8VSLavFz","colab_type":"code","colab":{}},"cell_type":"code","source":["### Decode the state result from the Pi matrix \n","def viterbi_result(text):\n","  V = viterbi_deconding(text)\n","  opt = []\n","  prev= None\n","  max_prob = max(value[\"prob\"] for value in V[-1].values())\n","  for st, data in V[-1].items():\n","    if data[\"prob\"] == max_prob:\n","      opt.append(st)\n","      previous = V[-1][st]['prev']\n","      break\n","  for t in range(len(V) - 2, -1, -1):\n","    opt.insert(0, previous)\n","    previous = V[t][previous][\"prev\"]\n","  return(opt)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"h4S-tPEpbWpa","colab_type":"code","colab":{}},"cell_type":"code","source":["### Access training accuracy\n","accuracy_train = 0\n","word_train = 0\n","start_count =0 \n","for text in train:\n","  pred = viterbi_result(text) \n","  start_count +=1 \n","  for i in range(len(pred)):\n","    word_train  += 1\n","    if text[i][1] == pred[i]:\n","      accuracy_train += 1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"A8-FJMVlgPG4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"c0fde004-b8f9-46a6-d82d-837049916e67","executionInfo":{"status":"ok","timestamp":1550298556786,"user_tz":480,"elapsed":1268673,"user":{"displayName":"Zhanlin Liu","photoUrl":"","userId":"07295131763425127630"}}},"cell_type":"code","source":["(accuracy_train-start_count*3)/(word_train-start_count*3)"],"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8367236476996335"]},"metadata":{"tags":[]},"execution_count":68}]},{"metadata":{"id":"OfUxRc7d2tna","colab_type":"code","colab":{}},"cell_type":"code","source":["### Access dev accuracy and confusion matrix\n","confusion_mat = np.zeros((len(unique_state), len(unique_state)))\n","confusion_res = pd.DataFrame(confusion_mat, columns=unique_state, index=unique_state)\n","accuracy = 0\n","word = 0"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Y69w9Qoi225a","colab_type":"code","colab":{}},"cell_type":"code","source":["for text in dev:\n","  pred = viterbi_result(text) \n","  for i in range(len(pred)):\n","    word  += 1\n","    #confusion_res[text[i][1]][pred[i]] += 1\n","    if text[i][1] == pred[i]:\n","      accuracy += 1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ESXrxJNq246R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"024e8016-6997-4822-a223-b8aaf3ab38e4","executionInfo":{"status":"ok","timestamp":1550298684674,"user_tz":480,"elapsed":1396544,"user":{"displayName":"Zhanlin Liu","photoUrl":"","userId":"07295131763425127630"}}},"cell_type":"code","source":["(accuracy - 5000*3)/(word- 5000*3)"],"execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8300017689722271"]},"metadata":{"tags":[]},"execution_count":71}]},{"metadata":{"id":"fGTrVwui5yhU","colab_type":"code","colab":{}},"cell_type":"code","source":["### Convert low frequent words in test set\n","for i in range(len(test)):\n","  for j in range(len(test[i])):\n","    if test[i][j][0] not in present_word:\n","      test[i][j][0] = get_type(test[i][j][0])\n","confusion_mat_test = np.zeros((len(unique_state), len(unique_state)))\n","confusion_res_test = pd.DataFrame(confusion_mat_test, columns=unique_state, index=unique_state)\n","accuracy_test = 0\n","word_test = 0\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5sX2ibpe32IP","colab_type":"code","colab":{}},"cell_type":"code","source":["### Access test accuracy\n","for text in test:\n","  pred = viterbi_result(text) \n","  for i in range(len(pred)):\n","    word_test  += 1\n","    if text[i][1] == pred[i]:\n","      accuracy_test += 1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dDXM6GIj5kgF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6deda5a3-b5de-48f8-8e2e-baea08d9c1f9","executionInfo":{"status":"ok","timestamp":1550298812055,"user_tz":480,"elapsed":1523912,"user":{"displayName":"Zhanlin Liu","photoUrl":"","userId":"07295131763425127630"}}},"cell_type":"code","source":["(accuracy_test - 5000*3)/(word_test-5000*3)"],"execution_count":74,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8312908885654829"]},"metadata":{"tags":[]},"execution_count":74}]},{"metadata":{"id":"JKckz87F6oZz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"d80166ec-acfe-4ed7-ab6a-806785d68a1d","executionInfo":{"status":"ok","timestamp":1550298812055,"user_tz":480,"elapsed":1523906,"user":{"displayName":"Zhanlin Liu","photoUrl":"","userId":"07295131763425127630"}}},"cell_type":"code","source":["len(test)"],"execution_count":75,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5000"]},"metadata":{"tags":[]},"execution_count":75}]},{"metadata":{"id":"aIL6S95T-DaL","colab_type":"code","colab":{}},"cell_type":"code","source":["## Output the mismatches and their counts \n","wrong_list ={}\n","for text in dev:\n","  pred = viterbi_result(text) \n","  for i in range(len(pred)):\n","    #word  += 1\n","    #confusion_res[text[i][1]][pred[i]] += 1\n","    if text[i][1] != pred[i]:\n","      wrong_list[(text[i][1], pred[i])] = wrong_list.get((text[i][1], pred[i]),0) +1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"chHfoIpK6pKw","colab_type":"code","colab":{}},"cell_type":"code","source":["###################################################\n","########### Trigram Viterbi algorithm ##############\n","##################################################\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"M0tbZYF7-MJz","colab_type":"code","colab":{}},"cell_type":"code","source":["#### get trigram state transition probabilities\n","trigram_state = dict()\n","for sentence in train:\n","  state_1 = None\n","  state_2 = None\n","  for word, state in sentence:\n","    if state_1 != None and state_2 != None:\n","      trigram_state[(state_1, state_2, state)] = trigram_state.get((state_1, state_2, state), 0) +1\n","    state_1 = state_2\n","    state_2 = state"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_MWxLQIE-NPq","colab_type":"code","colab":{}},"cell_type":"code","source":["def calculate_trigramHMM_probability_LP(state_1, state_2, state):\n","  if bigram_state.get((state_1, state_2), 0) ==0:\n","    return(1/unique_state_length)\n","  else:\n","    trigram_state_numerator = trigram_state.get((state_1, state_2, state), 0) \n","    trigram_state_denominator = bigram_state.get((state_1, state_2), 0)  \n","    return(trigram_state_numerator/trigram_state_denominator)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uUwj9MYW-Qt_","colab_type":"code","colab":{}},"cell_type":"code","source":["def calculate_trigram_interpolationHMM_probability(state_1, state_2, state):\n","  tri_prob = calculate_trigramHMM_probability_LP(state_1, state_2, state)\n","  bi_prob = calculate_bigramHMM_probability_LP(state_2, state)\n","  uni_prob = calculate_unigramHMM_probability_LP(state)\n","  res = lambda_1 * tri_prob + lambda_2 * bi_prob + lambda_3 * uni_prob \n","  return(res)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"c5uZgoaC-RVl","colab_type":"code","colab":{}},"cell_type":"code","source":["lambda_1 = 0.4\n","lambda_2 = 0.3\n","lambda_3 = 0.3\n","unique_state = unigram_state.keys()\n","def viterbi_deconding_trigram(text):\n","  V= [{}]\n","  state_1 = None\n","  state_2 = None\n","  for state in unique_state:\n","    if state == \"START_1\":\n","      V[0][state] = {\"prob\":1, \"state_1\":None, \"state_2\":None}\n","    else:\n","      V[0][state] = {\"prob\":0, \"state_1\":None, \"state_2\":None}\n","  for i in range(1, len(text)):\n","    V.append({})\n","    for state in unique_state:\n","      V[i][state] = {\"prob\":0, \"state_1\":None, \"state_2\":None}\n","    for state in unique_state:\n","      max_prob = 0\n","      for state_1 in unique_state:\n","        for state_2 in unique_state:\n","          prob = V[i-1][state_2]['prob'] * calculate_emissionHMM_probability_LP(text[i][0], state) * calculate_trigram_interpolationHMM_probability(state_1, state_2, state)\n","          if prob > max_prob:\n","            V[i][state] = {\"prob\": prob, \"state_1\":state_1, \"state_2\":state_2}\n","            max_prob = prob          \n","  return(V)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GTXMbhp6-VE0","colab_type":"code","colab":{}},"cell_type":"code","source":["def viterbi_result_trigram(text):\n","  V = viterbi_deconding_trigram(text)\n","  opt = []\n","  state_1 = None\n","  state_2 = None\n","  max_prob = max(value[\"prob\"] for value in V[-1].values())\n","  for st, data in V[-1].items():\n","    if data[\"prob\"] == max_prob:\n","      opt.append(st)\n","      state_1 = V[-1][st]['state_1']\n","      state_2 = V[-1][st]['state_2']\n","      break\n","  for t in range(len(V) - 2, -1, -1):\n","    opt.insert(0, state_2)\n","    state_2 = V[t][state_2][\"state_2\"]\n","  return(opt)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6PyvejM2BQVX","colab_type":"code","colab":{}},"cell_type":"code","source":["#viterbi_result_trigram(train[0])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"h-4ag52WA8Si","colab_type":"code","colab":{}},"cell_type":"code","source":["accuracy_train_tri = 0 \n","word_train = 0 \n","for text in train:\n","  pred = viterbi_result_trigram(text) \n","  for i in range(len(pred)):\n","    word_train += 1\n","    if text[i][1] == pred[i]:\n","      accuracy_train_tri +=1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ajt3nAC3Awsv","colab_type":"code","colab":{}},"cell_type":"code","source":["accuracy_tri = 0\n","word = 0\n","for text in dev:\n","  pred = viterbi_result_trigram(text) \n","  for i in range(len(pred)):\n","    word += 1\n","    if text[i][1] == pred[i]:\n","      accuracy_tri +=1"],"execution_count":0,"outputs":[]}]}